####################
#ANALISIS FACTORIAL#
####################
#MATRIZ CORRELACION=MATRIZ DE CARGA* MATRIZ DE CARGA(TRANSPUESTA)+FACTORES ESPECIFICOS
#CUANTO MAS CERCANO A 1 ES MUCHO MEJOR,OBVIAMENTE VA SER IGUAL 1 YO RETENGA 10 VARIABLES
#10 FACTORES COMUNES,PERO NO ESTOY REDUCIENDO LA DIMENSIONALIDAD Y ESO NO ES LA IDEA(REDUCIR)
#LA DIMENSIONALIDAD,LA IDEA ES TENER MENOR FACTORES COMUNES QUE EL NUMERO DE VARIABLES.
#(ESTO EXPLICA XQ TIENE QUE SER CERCANO A 1 Y NO EXACTAMENTE 1).
#1=h^2 + w^2, donde h^2 comunidad y w^2 especifidad.
#######################################################################################
#LO QUE QUIERO ESQ 'FACTORES DE COMUNIDAD' SEA LA PARTE QUE MAS EXPLIQUE LA VARIANCIA.#
#######################################################################################
#¿COMO HALLAR LAS 'CARGAS FACTORIALES' O PESOS O COEFIENCIENTES?
#LO RESPECTIVOs 'Lij'
#METODO DE COMPONENETES
#
#el modelo que deseo plantear es 'la variable igual factores comunes(F) + factores especificidad'(E)
#
#
#Y=L11*F1+L12*F2+...+L1m*Fm +E1
#
#revertir el sistema.
#
library(pacman)
p_load(rela, psych, ade4,GGally,PerformanceAnalytics)
# Lectura de datos con 7 variables
datos <- read.delim("hatco-factorial.txt")
str(datos)
# x7 : Servicio

# No considerar la primera columna Id
datos$id <- NULL
str(datos)

############################################
# 2. Análisis Exploratorio con 7 variables #                                       #
############################################

# Análisis Descriptivo y Análisis de Correlación
library(psych)
describe(datos)
cor(datos)

corr.test(datos)

library(PerformanceAnalytics)
chart.Correlation(datos, histogram=TRUE, pch=20)
#MAPA DE CALOR##SUGERENCIA usar- 'windows()'
library(psych)
cor.plot(cor(datos),
         main="Mapa de Calor", 
         diag=F,number=F,
         show.legend = T)  
#MAPA DE CALOR##SUGERENCIA usar- 'windows()'
library(GGally)
ggcorr(datos)

library(dataMaid)#nos genera un word,observacion,se tiene q cambiar de nombre 
#ya que genera un word unico.
makeCodebook(datos,file="datosfactorial")
#####################################
# Prueba de Esfericidad de Bartlett##
#####################################
library(rela)
options(scipen=0)  # scipen = 999 Eliminan la notación científica
cortest.bartlett(cor(datos),n=nrow(datos))
#pvalor es menor a 0.05,se rechaza la hipotesis nula H0.
# La matriz de correlación difirente a la matriz Identidad.

# Indicador Kaiser-Meyer-Olkinn KMO y MSA 
KMO(datos)

# Overall MSA =  0.45 <- KMO
#
#
#
# Lectura de datos con 6 variables
datos <- read.delim("hatco-factorial.txt")
str(datos)

# No considerar la primera columna Id ni la última variable X7
datos$id <- NULL
datos$x7 <- NULL
datos.facto <- datos
str(datos.facto)

# Analisis descriptivo y Analisis de Correlacion
library(psych)
describe(datos.facto)
cor(datos.facto)

corr.test(datos.facto)

library(PerformanceAnalytics)
chart.Correlation(datos.facto, histogram=TRUE, pch=20)

library(psych)
cor.plot(cor(datos.facto),
         main="Mapa de Calor", 
         diag=F,number=F,
         show.legend = T)  

# Prueba de Esfericidad de Bartlett
library(rela)
cortest.bartlett(cor(datos.facto),n=nrow(datos.facto))

# Indicador Kaiser-Meyer-Olkinn KMO y MSA 
KMO(datos.facto)
####
##
###
#######################################################
#ANALISIS FACTORIAL SIN ROTACION CON FUNCION PRINCIPAL#
#######################################################
library(psych)
facto.sin.rota <- principal(r=datos.facto,#r=matriz de correlacion
                            nfactors=2,#¿CUANTOS FACTORES?
                            covar = F,#¿QUIERES TRABAJAR CON LA MATRIZ VARIANCIA Y COVARIANCIA?RPTA:NO,yo quiero trbjar con los datos estandarizados
                            rotate="none")#no  quiero rotar
str(facto.sin.rota)

# Autovalores
facto.sin.rota$values
####
####
###
eig.val <- as.data.frame(facto.sin.rota$values)#guardando los autovalores en un dataframe.
#por que lo graficaremos en la sgt linea de codigo.
###criterio para determinar los factores.
library(ggplot2)
ggplot(eig.val) + aes(x=seq(1:6),y=facto.sin.rota$values) +
  geom_point(color="red") +
  scale_x_continuous(breaks=seq(1:6)) +
  labs(title="Scree-Plot",
       x= "Componentes",
       y= "Autovalor") +
  geom_col(fill="white",
           col="black") +
  geom_line() + 
  geom_hline(yintercept = 1,lty=2,color="blue") +
  geom_text(aes(label=round(facto.sin.rota$values,2) ), vjust=1.5,color="black") +
  theme_bw()
#####
#######################
#####comunalidades#####
#######################
facto.sin.rota$communality
#       x1        x2        x3        x4        x5        x6 
#0.6575783 0.5800456 0.6456241 0.8816649 0.8722222 0.6155984 
#interpretacion:
#el 65.75783% de la variabilidad de x1 esta explicada por los factores de comunes(compartida).
#(100-65.75)% de la varibilidad de x1 esta explicada por la misma variable o por su factor especifico(no compartido).
#¿que pasaria si x6 su comunalidad=0.2?
#agregar un factor,de 2 factores ahora serian 3 factores.
################### 
###especificidad###
###################
facto.sin.rota$uniquenesses    
# Cargas Factoriales, Correlaciones Factor, Variable
facto.sin.rota$loadings               

#     PC1    PC2   
# x1 -0.627  0.514     #0.627**2 + 0.514**2 = Comunalidad
# x2  0.759       
# x3 -0.730  0.336
# x4  0.494  0.799
# x5  0.424  0.832
# x6  0.767 -0.167
#
#0.627**2 + 0.514**2            #comunalidad
#facto.sin.rota$communality     #comunalidad
#####################
#modelo_de_factorial#
#####################
#x1=0.627*F1+0.514*F2 +e1
#.
#x6=0.767*F1-0.167*F2 +e2


# (-0.627, 0.514)  -> Cargas Factoriales (lij) 
#                     Correlaciones entre X(variable estandarizada) y F(se genero de la estandarizacion del componente 'y')
# 0,658 = 65,8% de la variabilidad de X1 es explicada 
#               por los factores comunes (F1, F2)

# Gráfica de circulo de correlaciones
library(ade4)
load.sin.rota <- facto.sin.rota$loadings[,1:2]
s.corcircle(load.sin.rota,grid=FALSE)
